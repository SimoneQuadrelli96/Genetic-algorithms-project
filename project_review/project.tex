\documentclass{article}

\usepackage{subfig}
\usepackage{float}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{changepage}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[driver=pdftex]{geometry}

\newtheorem{theorem}{Theorem}

\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}




\begin{document}
\begin{titlepage}
	
	
	\begin{center}
		\vspace{2 cm}
		{\Large \textsc{Simone Quadrelli} }
	\end{center}
	
	
	\begin{figure}[H]
		\vspace{2 cm}
		\centering
		\includegraphics[width=0.30\linewidth]{tesiSCIENZE_TECNOLOGIE.jpg}
		
	\end{figure}
	
	\begin{center}
		\vspace{2 cm}
		{\Large \textsc{Genetic algorithm Monte Carlo} }
	\end{center}

	\par
	\vspace{3 cm}
	
	\begin{center}
		{\large Academic year 2019 - 2020}
	\end{center}
\end{titlepage}

\pagenumbering{gobble}
\newpage 
\pagenumbering{roman}
\tableofcontents
\listoftables
\listoffigures
\newpage

\pagenumbering{arabic}

\section*{Abstract}
The aim of this project is to solve the travelling salesman problem (TSP) which consists in finding the shortest cycle among all the cities. The problem is a \textit{NP-hard} problem and therefore there exist no feasible algorithm to solve if for any possible set of cities in input. The appromximately optimal solution was computed by the simulated annealing, while the possible cycles are produced by a genetic algorithm.

\section{Introduction}
The travelling salesman problem consists in finding the shortest route a travelling salesman has to take to visit all the city he must reach only once and to return to the starting point. The route described is called in graph theory \textit{hamiltonian cycle} (i.e a cycle that pass through each vertex of a graph just once), indeed the oldest and more technical formulation of the problem was proposed by Hamilton. \\
An algorithm that provides a solution to TSP can be exploited in a wide variety of applications: indeed it can be used in logistics to optimize the path of vehicles and therefore to reduce costs.
It is possible to model the problem usign an undirected, weighted and fully connected graph \footnote{For an hamiltinian cycle to exist the graph must be at least connected} $G = (N,E)$, where $N$ is the set of the cities to visit and $E =  N \times N$ is the weight of the path. In this particular instance of the probelm the weights correspond to the euclidean between each couple of cities.
THe mailtonian cycle can be defined as a sequence $(n_0, .., n_{k-1})$ of length k such that $n_i \neq n_j \; \forall i,j \in \{1,..., |N|\}$ and such that $(i,j) \in E \; \forall i,j \in \{1,..., |N|\}$
The most naive solution is to compute all the possible paths but they are factorial in the number of cities $n$ in input. The number of possible cycles is $(n-1)!$ and grows faster that $2^n$ (i.e $2^n = o(n!)$). Therefore even if it was possible to find them in constant time the algorithm will have an expnential time complexity and would not be solved in finite time for large $n$. 
More techically, TSP is an NP-hard problem. A NP-hard problem is a problem at least as hard as the hardest NP-complete problem. NP-complete problem is a problem that can be solved in polynomial time by a non-deterministic algorithm. For such a class of problem there exists no polynomial algorithm that can solve the problems and may not exist, still noone was able to prove that such algorithms does not exists.
\begin{figure}
\includegraphics[scale=1]{complexity_classes.png} 
\centering
\end{figure}
Bearing in mind the complexity problem to face, the most reasonable solution is to solve the problem approximately. The technique I to generate the possible hamiltonian cycles is a genetic algorithm, while the choice of the fittest hamiltonian cycle is done by the simulated annealing algorithm

\section{Simulated annealing}
Simulated annealing (SA) is a technique that mimic the behaviour of heated materials in metallurgy that can be slowly cooled down, this process decreases the impurity and increases the size of the crystals. It is a technique that pproximates the global optimal solution when the solutions is to be searched in an enormous space. SA is a metaheuristic meaning that it is not a probelm specific heuristic and that can be used to reduce the search space of an algorithm, the genetic algorithm in our case.\\
SA very usefull since it does not require any prior information, indeed it just supposes that the states (hamiltonian cycles in our case) are distributed accordingly to the Bolzmann distribution:
\begin{equation}
\exp^{- \beta (cost(new state) - cost(old state))}
\end{equation}
The temperature $T$ stated before is $T = \frac{1}{\beta}$, therefore we start with low values of betas (high temperature) and as the simulation proceeds we increase the values of $\beta$, thus mimicing the decrease in temperature.
The only other information needed is the cost function. For this specific application the cost function is the euclidean distance between the cities. The $(x,y)$ are expressed in latitude and longitude (CONTROLLA L'ORDINE). Therefore given the coordinates of two cities  $(x_1,y_1)$ and $(x_3,y_2)$
\begin{equation}
cost((x_1,y_1),(x_2,y_2)) = \sqrt{(x_1-x_2)^2 + (y_1-y_2)^2}
\end{equation}

\begin{algorithm}[h]
    \begin{algorithmic}[1]
      \Function{simulated annealing}{}
        \State s $\leftarrow$ generate starting state
         \For {b in \textbf{betas}}
         	\For{n in 1,.., number of simulations}
         	\State ns  $\leftarrow$ sample new states with metropolis algorithm
         	\EndFor
        \EndFor
        \State return ns
       \EndFunction
\end{algorithmic}
\end{algorithm}

\section{Metropolis algorithm}
Metropolis is a Markov Chain Monte Carlo (MCMC) algorithm used to generate values from a finite set of values $S$ accordingly to a target probability distribution $\pi$. It is designed in such a way that it is very lilely to move from a state with lower probability from a stete with higher probability. \\
The following algorithms describes the metropolis algorithm when the target distribution is $\pi(\text{state}) = \exp^{\beta \text{cost(state)}}$ and $S$ is the set of all possible hamiltonian cycles having fixed their length. In the following we suppose to have generated two hamiltonian cycles (i.e states) old\_state, new\_state and we want to understand if new\_state can come from $\pi$. If new\_state is likely to be a sample of $\pi$ we use it as new state otherwise we keep old\_state as the current state.
\begin{algorithm}[H]
    \begin{algorithmic}[1]
      \Function{metropolis}{old\_state, new\_state}
      	\If {cost(new\_state) $<$ cost(new\_state)}
      	\State return new\_state
      	\EndIf
        \State threshold $\leftarrow$ unif[0,1]
        \State p  $\leftarrow min\{1,\exp^{- \beta (cost(new\_state) - cost(old\_state))} \}$ 
        \If {p $>$ threshold}
        	\State return new\_state
        \Else
        	\State returm old\_state
        \EndIf
       \EndFunction
\end{algorithmic}
\end{algorithm}
\noindent
\subsection{Properties of metropolis algorithm}
We can model the generation of new hamiltonian cycles usign a undirected and connected graph $G = (S,E)$ whose set of states $S$ contains all the possible hamiltonian cycles and $E$ contains the transition probability from an hamiltonian cycle to another one. Given the graph, we can define the transition matrix $P=p(i,j)]_{i,j\in S}$ as
\begin{equation}
p(i,j) =  \begin{cases} 
	0\, & \mbox{if } \{i,j\} \notin E  \\ 
	\frac{1}{d_i} \min\{1,\frac{\pi(j)}{\pi(i)}\} & \mbox{if }  \{i,j\} \in E \; i \neq j\\
	\frac{1}{d_i} \sum_{l \in adj(i)} \min\{1,\frac{\pi(l)}{\pi(i)}\}  & \mbox{if }  i = j 
\end{cases}
\end{equation}
Since G is a connected graph, the $P$ is irriducible meaning that $\forall i,j \in S \, p^n(i,j) > 0$, where $p^n(i,j)$ means that exist a path from $i$ to $j$ of length $n$.\\
It can also be proved that $P$ is aperiodic \cite{metropolis}. By aperidoicity we mean each node of the graph has a loop. More formally, th graph $G$ is aperiodic if $\forall i \in S, \,d(i)  = 1$ where
\begin{equation}
d(i) = mcd \{n \in N | \, \text{exist a cycle from i to i of length} \, n\}
\end{equation}
Metropolis algorithm defines a probability distributin $\pi$ that is a reversible distribution, meaning that
\begin{equation}
	\pi(i)p(i,j) = \pi(j)p(j,i) \;\; \forall i,j \in S
\end{equation}
This is a key feature of the algorithm since a reversible distribution $\pi$ is also a stationary distribution $\pi'P=\pi'$. This condition holds by the following theprem
\begin{theorem}
If a probability distribution $\pi$ is a reversible distribution for a markov chain $ \{X_n\} $, then it is also a stationary distribution.
\end{theorem}

\begin{proof}
$ (\pi'P)_j = sum_{i \in S} \pi(i)p(i,j) = \sum_{i \in S} \pi(j)p(j,i) = \pi(j) $ 
\end{proof}
If this distribution was unique than we are certain to correctly generate the data accordingly to the target distribution. The stationary distibution is unique if the transition matrix is primitive as stated by the follwing theorem.
\begin{theorem}
Let $\{X_n\}$ be a markov chain with a primitive (i.e primitive and aperiodic) transition matrix on a finite set, then  there exist only one stationary distribution and it as also the limit distribution $\lim_{x \to \infty} p^n(i,j) = \pi(j)\,  \forall i \in S$
\end{theorem}
Since $P$ is primitive is enough to compute the limit distribution to find the stationay distribution. \\
The stationary distribution can be approximated
Markov chains converge exponentially fast to the stationary distibution starting from any distribution. To sample hamiltonian cycle from the correct distribution is enough to let the simulation go on for a suitable number of iterations. \\
Metrpolis algorithm comnverges to the stationary distribution in logarithmic time, having fixed the approximation. Therefore we execute in for a sufficient number of iterations to converge to the stationary distribution. Then we change the value of $\beta$ in the simulated annealing to proceed toward the optimum.

\section{Genetic Algotirthm}
Genetic algorithms are a widespread class of algotirhms that mimic nature. Indeed there are three fundamental operations they perform, each operation is inspired by the theory of evolution by Darwin. Among a specie evolution selects the fittest individuals and therefore the algorithm will chose the fittest (i.e shortest) hamiltonian cycles. The breeding of the fittest individuals produces new individuals that inherits traits from the parents, therefore in the crossbreeding phase we mix some subsection of the fittest hamiltonian cycles.
As random mutations can occur in nature but they are not so likely to accur, the algorithms swaps two nodes (cities) with a fixed and low probability.
My own implementation of the algorithms performs the selection operation as follows:
\begin{algorithm}[H]
    \begin{algorithmic}[1]
      \Function{selection}{\textbf{population},n\_paths}
        \State $n\_parents \leftarrow$ unif[2,n\_paths/2]
        \State order the population by fitness
        \State \textbf{fittest\_subpopulation} $\leftarrow$ extract $n\_parents$ in order from the sorted population
        \State return \textbf{fittest\_subpopulation}
       \EndFunction
\end{algorithmic}
\end{algorithm}
\noindent where \textbf{population} is an array of hamiltonian cycles

\begin{algorithm}[H]
    \begin{algorithmic}[1]
      \Function{crossbreeding}{\textbf{fittest\_subpopulation}}
      	\For {i in 1, ..., n\_paths}
  			\State choose parent1 uniformely among the \textbf{fittest\_subpopulation}
  			\State Choose parent2 uniformely among the \textbf{fittest\_subpopulation}
  			\If {parent1 different from parent2}
  				\State choose position1 randomly among unif([0,length of cycles-1)
  				\State choose position2 randomly among unif([0,length of cycles-1)
  				\State divide parent1 in three sections: 
  				\State[parent10:position1] 
  				\State parent1[position1:position2]
  				\State parent1[posotion2:]
  				\State divide parent2 in three sections:
  				\State parent2[0:position1] 
  				\State parent2[position1:position2]
  				\State parent2[posotion2:]
  				\State breed child1 justapposing in the order:
  				\State parent1[0:position1]
  				\State all the cities not in  parent1[0:position1] and not in parent2[posotion2:]
  				\State parent2[posotion2:]
  				\State breed child2 justapposing in the order:
  				\State parent2[0:position1]
  				\State all the cities not in  parent2[0:position1] and not in parent1[posotion2:]
  				\State parent1[posotion2:]
  			\Else
  				\State child1 $\leftarrow$ parent1
  				\State child2 $\leftarrow$ parent1
  			\EndIf
      	\EndFor
        \State \textbf{new\_population} is a vector of the children 
       \EndFunction
\end{algorithmic}
\end{algorithm}
2) Crossbreeding --> obtain new hamiltonian cycles exchanging the gines of the parents
3) Mutation --> exchange genes randomly
\begin{algorithm}[H]
    \begin{algorithmic}[1]
      \Function{mutate}{\textbf{new\_population}, p}
        \State test $\leftarrow$ unif[0,1]
        \If {test $<$ p}
        	\State choose position1 randomly among unif([0,length of cycles-1)
  			\State choose position2 randomly among unif([0,length of cycles-1)
  			\State swap the cities in position1 and position2
        \EndIf
        \State order the population by fitness
        \State \textbf{fittest\_subpopulation} $\leftarrow$ extract $n\_parents$ in order from the sorted population
        \State return \textbf{fittest\_subpopulation}
       \EndFunction
\end{algorithmic}
\end{algorithm}


\begin{algorithm}[H]
    \begin{algorithmic}[1]
      \Function{evolve}{\textbf{population}}
        \State \textbf{fittest\_population} $\leftarrow$ SELECT(\textbf{population})
        \State \textbf{new\_population} $\leftarrow$ CROSSBREED(\textbf{fittest\_population})
       \State \textbf{population} $\leftarrow$ MUTATE(\textbf{new\_population})
       \EndFunction
\end{algorithmic}
\end{algorithm}
\section{dataset}

\section{results}

\begin{thebibliography}{9}

\bibitem{metropolis}
Oliver Catoni
\textit{Simulated annealing algorithms and Markov chains with rare transitions}, Séminaire de probabilités (Strasbourg), tome 33 (1999), p. 69-119.


\bibitem{reducing dimesionality} 
G. E. Hinton and R.R. Salakhutdinov, 
\textit{Reducing the Dimensionality of Data with Neural Networks}. 
Science, 29 July 2006, Vol 313, 504-507.
 


\end{thebibliography}

\end{document}